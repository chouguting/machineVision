{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "hw1_input_video = cv2.VideoCapture('homework_1_test_video.mp4')  #輸入的影片\n",
    "hw1_output_video = cv2.VideoWriter('myHW1Video.mp4', cv2.VideoWriter_fourcc(*'XVID'),\n",
    "                                   hw1_input_video.get(cv2.CAP_PROP_FPS),\n",
    "                                   (int(hw1_input_video.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                                    int(hw1_input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))))  #輸出的影片"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 設定基本資訊"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "frame_num = 0\n",
    "total_frame = int(hw1_input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\n",
    "## 設定是第幾個frame\n",
    "def set_frame_number(x):\n",
    "    global frame_num\n",
    "    frame_num = x\n",
    "    return\n",
    "\n",
    "\n",
    "cv2.namedWindow('hw1 video file')  ##預覽視窗的名字\n",
    "cv2.createTrackbar('progress', 'hw1 video file', 0, total_frame - 1, set_frame_number)  #設定進度條(滑桿)的名字，預設值，最小值，最大值，設定滑桿的值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 取得YouTube上的影片"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pafy\n",
    "import time\n",
    "\n",
    "#設定要播放的Youtube影片\n",
    "url = \"https://youtu.be/PHqhEgkGfrs\"\n",
    "ty_video = pafy.new(url, basic=False, gdata=False)\n",
    "best = ty_video.getbest(preftype=\"mp4\")\n",
    "youtube_video = cv2.VideoCapture(best.url)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 平均濾波"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def mean_filter(image, kernel_size):\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.float32) / (kernel_size * kernel_size)\n",
    "    return cv2.filter2D(image, -1, kernel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 傅立葉高通濾波"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def fft_high_pass_filter(image, freq_cutoff):\n",
    "    fft_image = np.fft.fft2(image.copy())\n",
    "    fft_image = np.fft.fftshift(fft_image)\n",
    "    cy, cx = fft_image.shape[0]/2,fft_image.shape[1]/2\n",
    "    h = np.arange(fft_image.shape[0]).reshape((-1,1)) - cy\n",
    "    w = np.arange(fft_image.shape[1]).reshape((1,-1)) - cx\n",
    "    #freq_cutoff = freq_cutoff**2\n",
    "    fft_image[:,:,0] =  np.where((h**2)/((freq_cutoff)**2)+w**2/((0.2*freq_cutoff)**2)>=1,fft_image[:,:,0],0)\n",
    "    fft_image[:,:,1] =  np.where((h**2)/((freq_cutoff)**2)+w**2/((0.2*freq_cutoff)**2)>=1,fft_image[:,:,1],0)\n",
    "    fft_image[:,:,2] =  np.where((h**2)/((freq_cutoff)**2)+w**2/((0.2*freq_cutoff)**2)>=1,fft_image[:,:,2],0)\n",
    "    fft_image = np.fft.ifftshift(fft_image)\n",
    "    fft_image = np.fft.ifft2(fft_image)\n",
    "    fft_image = np.abs(fft_image)\n",
    "    return fft_image\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 利用TENSORFLOW做卷積"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def tf_conv_BGRToYIQ(image):\n",
    "    kernel = np.zeros((1,1,3,3), np.float32)\n",
    "    kernel[0,0,:,:] = np.array([[0.3, 0.59, 0.11],\n",
    "                                [0.6, -0.28, -0.32],\n",
    "                                [0.21, -0.52, 0.31]])\n",
    "    kernel = tf.constant(kernel, dtype=tf.float32)\n",
    "    image = tf.constant(np.expand_dims(image,axis=0), dtype=tf.float32)\n",
    "    return tf.nn.conv2d(image, kernel, strides=[1, 1], padding='SAME').numpy()\n",
    "\n",
    "def tf_conv_YIQtoBGR(image):\n",
    "    kernel = np.zeros((1,1,3,3), np.float32)\n",
    "    kernel[0,0,:,:] = np.array([[1, 0.95, 0.62],\n",
    "                                [1, -0.28, -0.64],\n",
    "                                [1, -1.1, 1.72]])\n",
    "    kernel = tf.constant(kernel, dtype=tf.float32)\n",
    "    image = tf.constant(np.expand_dims(image,axis=0), dtype=tf.float32)\n",
    "    return tf.nn.conv2d(image, kernel, strides=[1, 1], padding='SAME').numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "while frame_num < total_frame:\n",
    "    cv2.setTrackbarPos('progress', 'hw1 video file', frame_num)  #設定進度條的值\n",
    "    hw1_input_video.set(cv2.CAP_PROP_POS_FRAMES, frame_num)  #設定要讀取的frame\n",
    "    youtube_video.set(cv2.CAP_PROP_POS_FRAMES, frame_num)  #設定要讀取的frame\n",
    "\n",
    "    ret, frame = hw1_input_video.read()  #讀取那個frame   frame是 高*宽*3的矩阵  #ret是布林值，是否有讀到影片的下一幀\n",
    "    ret_yt, frame_yt = youtube_video.read()  #讀取那個frame   frame是 高*宽*3的矩阵  #ret是布林值，是否有讀到影片的下一幀\n",
    "\n",
    "    output_frame = np.zeros((frame.shape[0], frame.shape[1], frame.shape[2]), dtype=np.uint8) #設定一個空的矩陣(輸出用)\n",
    "\n",
    "\n",
    "\n",
    "    #resize輸入維度是 寬*高\n",
    "    ytFrame_resize = cv2.resize(frame_yt, (int(frame.shape[1] / 2), int(frame.shape[0] / 2))) #Youtube影片frame的縮放\n",
    "    one_fourth_frame = cv2.resize(frame, (int(frame.shape[1] / 2), int(frame.shape[0] / 2)))  #輸入影片的縮放\n",
    "\n",
    "    mean_filtered_frame = mean_filter(one_fourth_frame, 20)  #做平均濾波\n",
    "    high_pass_filtered_frame = fft_high_pass_filter(one_fourth_frame, 272)  #做傅立葉高通濾波\n",
    "    hsv_frame = cv2.cvtColor(one_fourth_frame, cv2.COLOR_BGR2HSV) #色彩空間轉換\n",
    "    hsv_frame[:,:,1] = hsv_frame[:,:,1]*1.5\n",
    "    hsv_frame =  cv2.cvtColor(one_fourth_frame, cv2.COLOR_HSV2BGR).clip(0,255)\n",
    "\n",
    "    YIQ_frame = tf_conv_BGRToYIQ(ytFrame_resize)\n",
    "    YIQ_frame[:,:,:,1] = YIQ_frame[:,:,:,1] * 0\n",
    "    YIQ_frame[:,:,:,2] = YIQ_frame[:,:,:,2] * 0\n",
    "    YIQ_frame = tf_conv_YIQtoBGR(YIQ_frame)\n",
    "    YIQ_frame = np.squeeze(YIQ_frame).astype(int).clip(0,255)\n",
    "\n",
    "    output_frame[0:int(frame.shape[0] / 2), 0:int(frame.shape[1] / 2), :] = YIQ_frame  #左上角放Youtube影片\n",
    "    output_frame[0:int(frame.shape[0] / 2), int(frame.shape[1] / 2):frame.shape[1], :] = hsv_frame\n",
    "    output_frame[int(frame.shape[0] / 2):frame.shape[0], 0:int(frame.shape[1] / 2), :] = mean_filtered_frame\n",
    "    output_frame[int(frame.shape[0] / 2):frame.shape[0], int(frame.shape[1] / 2):frame.shape[1],\n",
    "    :] = high_pass_filtered_frame\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.putText(img=output_frame, text='YIQ without IQ(using tensorflow)', org=(10, 60), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(0, 255, 0),thickness=1)\n",
    "    cv2.putText(img=output_frame, text='average filtering', org=(10, 1030), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(0, 255, 0),thickness=1)\n",
    "    cv2.putText(img=output_frame, text='HSV with higher Saturation', org=(1430, 60), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(200, 18, 255),thickness=1)\n",
    "    cv2.putText(img=output_frame, text='fourier high pass filtering', org=(1450, 1030), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(0, 255, 0),thickness=1)\n",
    "\n",
    "    previewFrame = cv2.resize(output_frame, (1280, 720))\n",
    "    cv2.imshow('hw1 video file', previewFrame)\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "    frame_num += 1\n",
    "    hw1_output_video.write(output_frame)\n",
    "hw1_input_video.release()\n",
    "hw1_output_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}