{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 使用ChArUco Board做相機校正\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 先取得校正要用到的點"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height 1080.0, width 1920.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "\n",
    "cap = cv2.VideoCapture('CharUco_board.mp4') # 取得攝影機\n",
    "#原始畫面有點大，為了有利於顯示這份講義所以縮小。\n",
    "totalFrame   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))//2\n",
    "frameHeight  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))//2\n",
    "\n",
    "arucoParams  = aruco.DetectorParameters_create()  # 建立Aruco參數(detectMarker process會用到)\n",
    "arucoParams.cornerRefinementMethod = aruco.CORNER_REFINE_SUBPIX  #用subpixel的方式來收細角點\n",
    "\n",
    "arucoDict    = aruco.Dictionary_get(aruco.DICT_6X6_250)  #我們用的是這個參數產生的ChArUco board\n",
    "\n",
    "# 必須描述ChArUco board的尺寸規格\n",
    "gridX        = 5 # 水平方向5格\n",
    "gridY        = 7 # 垂直方向7格\n",
    "squareSize   = 4 # 每格為4cmX4cm\n",
    "# ArUco marker為2cmX2cm\n",
    "charucoBoard = aruco.CharucoBoard_create(gridX,gridY,squareSize,squareSize/2,arucoDict)  # 建立ChArUco board\n",
    "\n",
    "print('height {}, width {}'.format(cap.get(cv2.CAP_PROP_FRAME_HEIGHT),cap.get(cv2.CAP_PROP_FRAME_WIDTH))) # 取得攝影機的長寬\n",
    "refinedStrategy = True  #\n",
    "criteria        = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.00001)\n",
    "frameId        = 0\n",
    "collectCorners = []\n",
    "collectIds     = []\n",
    "collectFrames  = []\n",
    "while True:\n",
    "    ret, frame = cap.read()  # 讀取一幀影像\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame,(frameWidth,frameHeight))  # 縮小畫面\n",
    "    (corners, ids, rejected) = aruco.detectMarkers(frame, arucoDict, parameters=arucoParams)  #偵測Aruco marker的角點位置(每個marker的四個角點), ids是每個marker的id, rejected是有錯或信心不足的marker的corner(也許是不符呵我們設定的DICT_6X6_250)\n",
    "\n",
    "    #corners是17個 4*2的陣列(代表每個marker的四個角點)\n",
    "    #ids是17個 1*1的陣列(代表每個marker的id) 每個marker的id是唯一的\n",
    "    #rejected是多個 4*2的陣列(代表每個rejected的四個角點)\n",
    "\n",
    "    #refinedStrategy代表是否用板子資訊去強化arucro的偵測\n",
    "    #這個一定要在detectMarker之後再做\n",
    "    if refinedStrategy:\n",
    "        corners, ids, _, _ = aruco.refineDetectedMarkers(frame,charucoBoard,corners,ids,rejected)\n",
    "\n",
    "    #每100個frame存一次之後校正要用到的點對應關係\n",
    "    if frameId % 100 == 50 and len(ids)==17: # 17 ArUco markers 如果全部正確被讀到才起來\n",
    "        collectCorners.append(corners)\n",
    "        collectIds.append(ids.ravel())\n",
    "        collectFrames.append(frame)\n",
    "\n",
    "    if len(corners) > 0:\n",
    "        aruco.drawDetectedMarkers(frame, corners, ids)  #把marker的角點畫出來\n",
    "\n",
    "    cv2.imshow('find points for calibration',frame)\n",
    "    if cv2.waitKey(20) != -1:\n",
    "        break\n",
    "\n",
    "    frameId += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 開始校正"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[913.01878047   0.         479.68086947]\n",
      " [  0.         920.3179607  293.38804426]\n",
      " [  0.           0.           1.        ]]\n",
      "[[ 0.0678466 ]\n",
      " [-0.11907327]\n",
      " [-0.0044268 ]\n",
      " [-0.00262406]\n",
      " [ 0.00265484]]\n",
      "(array([[ 1.85578111],\n",
      "       [ 2.13572257],\n",
      "       [-0.43417398]]), array([[ 2.02390891],\n",
      "       [ 2.16242677],\n",
      "       [-0.37060299]]), array([[ 1.95372558],\n",
      "       [ 2.13947932],\n",
      "       [-0.43930413]]), array([[ 2.07463475],\n",
      "       [ 2.14272052],\n",
      "       [-0.22373451]]), array([[ 1.84966262],\n",
      "       [ 2.40866435],\n",
      "       [-0.12727971]]), array([[ 2.01004494],\n",
      "       [ 2.25552498],\n",
      "       [-0.31535423]]), array([[ 2.03671404],\n",
      "       [ 2.15606694],\n",
      "       [-0.52940489]]), array([[ 2.12747067],\n",
      "       [ 2.19250079],\n",
      "       [-0.09167031]]), array([[ 2.22641555],\n",
      "       [ 2.13736037],\n",
      "       [-0.11893928]]), array([[ 2.23526767],\n",
      "       [ 2.0336658 ],\n",
      "       [-0.02519255]]), array([[ 2.23620562],\n",
      "       [ 2.0917037 ],\n",
      "       [-0.14035539]]))\n",
      "(array([[-12.15349024],\n",
      "       [-10.66690443],\n",
      "       [ 56.93386242]]), array([[-13.38816521],\n",
      "       [-18.24933705],\n",
      "       [ 59.09077561]]), array([[-10.81019063],\n",
      "       [ -8.95113039],\n",
      "       [ 59.2040962 ]]), array([[-18.98192181],\n",
      "       [-17.07542536],\n",
      "       [ 60.30016884]]), array([[-11.67661126],\n",
      "       [-18.0163875 ],\n",
      "       [ 58.55450786]]), array([[-14.5510487 ],\n",
      "       [-14.43541663],\n",
      "       [ 54.8673783 ]]), array([[-9.26340657],\n",
      "       [-9.75172933],\n",
      "       [52.5930739 ]]), array([[-20.44186679],\n",
      "       [-15.23034521],\n",
      "       [ 53.29462733]]), array([[-17.38064094],\n",
      "       [-11.24572572],\n",
      "       [ 52.45451233]]), array([[-23.96870427],\n",
      "       [-10.70161646],\n",
      "       [ 48.7157851 ]]), array([[-17.64375399],\n",
      "       [ -8.9092138 ],\n",
      "       [ 51.339221  ]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#把所有的校正要用到的點重新縮放後放到一個陣列中\n",
    "#reshape中的-1代表讓電腦判斷那個維度\n",
    "#collectCorners原本是好幾組的 17*(1*4*2)的陣列\n",
    "#把它轉成好幾組的(4*2)的陣列\n",
    "caliCorners=np.concatenate([np.array(x).reshape(-1,4,2) for x in collectCorners],axis=0)\n",
    "counter=np.array([len(x) for x in collectIds]) #計算每筆DATA收集到多少點\n",
    "caliIds=np.array(collectIds).ravel()  #把collectCorners所對應的ID排成一排，讓他和caliCorners一致\n",
    "#初始化內部參數\n",
    "cameraMatrixInit = np.array([[ 1000.,    0., frameWidth/2.],[    0., 1000., frameHeight/2.],[    0.,    0.,           1.]])\n",
    "#初始化畸形變參數\n",
    "distCoeffsInit   = np.zeros((5,1))\n",
    "#用charucoBoard及收集到的點還來做校正\n",
    "#給他收集到點的Aruco的角點、這些Aruco對應的ID、及ChArUco board板子布局\n",
    "#他就會回傳內部參數(cameraMatrix),外部參數(rvects和tvects),及失真參數(distCoeffs)\n",
    "ret, aruco_cameraMatrix, aruco_distCoeffs, aruco_rvects, aruco_tvects = aruco.calibrateCameraAruco(caliCorners,caliIds,counter,charucoBoard,(frameWidth,frameHeight),cameraMatrixInit,distCoeffsInit)\n",
    "print(aruco_cameraMatrix)\n",
    "print(aruco_distCoeffs)\n",
    "print(aruco_rvects)\n",
    "print(aruco_tvects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "caliCorners=[]\n",
    "caliIds    =[]\n",
    "#把每一個CharucoBoard當作一個整體來做校正\n",
    "for corners, ids, frame in zip(collectCorners,collectIds,collectFrames):\n",
    "    #\n",
    "    ret, charucoCorners, charucoIds = aruco.interpolateCornersCharuco(corners,ids,frame,charucoBoard,aruco_cameraMatrix,aruco_distCoeffs)\n",
    "    caliCorners.append(charucoCorners) #存板子內所有CORNER\n",
    "    caliIds.append(charucoIds)  #存板子內所有ARUCO ID的排列\n",
    "\n",
    "#用CharucoBoard校正\n",
    "#一樣可以得到內部參數(cameraMatrix),外部參數(rvects和tvects),及失真參數(distCoeffs)\n",
    "ret, charuco_cameraMatrix, charuco_distCoeffs, charuco_rvects, charuco_tvects = aruco.calibrateCameraCharuco(caliCorners,caliIds,charucoBoard,(frameWidth,frameHeight), aruco_cameraMatrix,aruco_distCoeffs)\n",
    "print(charuco_cameraMatrix)\n",
    "print(charuco_distCoeffs)\n",
    "print(charuco_rvects)\n",
    "print(charuco_tvects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 用校正好的相機找到每個CharUco_board的位置(3D位置)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#原始畫面有點大，為了有利於顯示這份講義所以縮小。\n",
    "cap = cv2.VideoCapture('CharUco_board.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame,(frameWidth,frameHeight))\n",
    "    (corners, ids, rejected) = aruco.detectMarkers(frame, arucoDict, parameters=arucoParams)\n",
    "\n",
    "    if ids is not None and len(ids)>0:\n",
    "        aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "        ret, rvect, tvect = aruco.estimatePoseBoard(corners, ids, charucoBoard, charuco_cameraMatrix, charuco_distCoeffs, None, None)\n",
    "        if ret:\n",
    "            aruco.drawAxis(frame, charuco_cameraMatrix, charuco_distCoeffs, rvect, tvect, squareSize)\n",
    "\n",
    "    cv2.imshow('Estimation of the pose of a CharUco board with intrinsic camera parameters by charuco',frame)\n",
    "    if cv2.waitKey(20) != -1:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#原始畫面有點大，為了有利於顯示這份講義所以縮小。\n",
    "cap = cv2.VideoCapture('CharUco_board.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame,(frameWidth,frameHeight))\n",
    "    (corners, ids, rejected) = aruco.detectMarkers(frame, arucoDict, parameters=arucoParams)\n",
    "\n",
    "    if ids is not None and len(ids)>0:\n",
    "        aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "        ret, rvect, tvect = aruco.estimatePoseBoard(corners, ids, charucoBoard, aruco_cameraMatrix, aruco_distCoeffs, None, None)\n",
    "        if ret:\n",
    "            aruco.drawAxis(frame, aruco_cameraMatrix, aruco_distCoeffs, rvect, tvect, squareSize)\n",
    "\n",
    "    cv2.imshow('Estimation of the pose of a CharUco board with intrinsic camera parameters by aruco',frame)\n",
    "    if cv2.waitKey(20) != -1:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 用校正好的相機找到每個Aruco的位置"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "markerSize  = 6 #6cm\n",
    "cap = cv2.VideoCapture('ArUco_marker.mp4')\n",
    "arucoDict   = aruco.Dictionary_get(aruco.DICT_7X7_50)\n",
    "totalFrame   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))//2\n",
    "frameHeight  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))//2\n",
    "\n",
    "hw2_output_video = cv2.VideoWriter('myHW2Video.mp4', cv2.VideoWriter_fourcc(*'XVID'),\n",
    "                                   cap.get(cv2.CAP_PROP_FPS),\n",
    "                                   (frameWidth,frameHeight))  #輸出的影片\n",
    "\n",
    "nggyu_cap = cv2.VideoCapture('nggyu.mp4')\n",
    "hyyyy_cap = cv2.VideoCapture('hyyyy.mp4')\n",
    "esg_cap   = cv2.VideoCapture('esg.mp4')\n",
    "ncat_cap = cv2.VideoCapture('ncat.mp4')\n",
    "game_cap = cv2.VideoCapture('game.mp4')\n",
    "vibe_cap = cv2.VideoCapture('vibe.mp4')\n",
    "\n",
    "has_started = [False for _ in range(6)] #紀錄哪些id開始被偵測到了\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    _, nggyu_frame = nggyu_cap.read()\n",
    "    _, hyyyy_frame = hyyyy_cap.read()\n",
    "    _, esg_frame = esg_cap.read()\n",
    "    _, ncat_frame = ncat_cap.read()\n",
    "    _, game_frame = game_cap.read()\n",
    "    _, vibe_frame = vibe_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame,(frameWidth,frameHeight))\n",
    "    frame = cv2.undistort(frame, charuco_cameraMatrix, charuco_distCoeffs)\n",
    "\n",
    "    # #把nggyu影片貼合到一張新影像的左上角\n",
    "    # nggyu_frame_full = np.zeros((frame.shape[0], frame.shape[1], frame.shape[2]),dtype=np.uint8)\n",
    "    # nggyu_frame_full[:360,:480]=nggyu_frame[:360,90:90+480]\n",
    "    #\n",
    "    # #把hyyyy影片貼合到一張新影像的左上角\n",
    "\n",
    "    #這些影片有黑邊，所以把他們切掉\n",
    "    nggyu_frame_crop = np.zeros((nggyu_frame.shape[0], 460, nggyu_frame.shape[2]),dtype=np.uint8)\n",
    "    nggyu_frame_crop[:,:,:]=nggyu_frame[:,90:550,:]\n",
    "\n",
    "    ncat_frame_crop = np.zeros((ncat_frame.shape[0], 550, ncat_frame.shape[2]),dtype=np.uint8)\n",
    "    ncat_frame_crop[:,:,:]=ncat_frame[:,85:635,:]\n",
    "\n",
    "    esg_frame_crop = np.zeros((360, esg_frame.shape[1], esg_frame.shape[2]),dtype=np.uint8)\n",
    "    esg_frame_crop[:,:,:]=esg_frame[60:420,:,:]\n",
    "\n",
    "\n",
    "\n",
    "    #print(nggyu_frame_crop.shape)\n",
    "\n",
    "    (corners, ids, rejected) = aruco.detectMarkers(frame, arucoDict, parameters=arucoParams)\n",
    "\n",
    "    if len(corners) > 0:\n",
    "        #aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "        rvects, tvects, _ = aruco.estimatePoseSingleMarkers(corners, markerSize, charuco_cameraMatrix, charuco_distCoeffs)\n",
    "        for corner,id in zip(corners,ids):\n",
    "            if id == 1:\n",
    "                mask_image = np.ones_like(vibe_frame)\n",
    "                source_pts = np.array([[640.0,360.0],[0.0,360.0],[0.0,0.0],[640.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(vibe_frame, M, (frameWidth, frameHeight), flags=cv2.INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 2:\n",
    "                mask_image = np.ones_like(esg_frame_crop)\n",
    "                source_pts = np.array([[640.0,360.0],[0.0,360.0],[0.0,00.0],[640.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(esg_frame_crop, M, (frameWidth, frameHeight), flags=cv2.INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 3:\n",
    "                mask_image = np.ones_like(nggyu_frame_crop)\n",
    "                source_pts = np.array([[460,360.0],[0.0,360.0],[0.0,0.0],[460.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(nggyu_frame_crop, M, (frameWidth, frameHeight), flags=cv2.INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 4:\n",
    "                mask_image = np.ones_like(hyyyy_frame)\n",
    "                source_pts = np.array([[480.0,360.0],[0.0,360.0],[0.0,0.0],[480.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(hyyyy_frame, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 5:\n",
    "                mask_image = np.ones_like(ncat_frame_crop)\n",
    "                source_pts = np.array([[550.0,480.0],[0.0,480.0],[0.0,0.0],[550.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(ncat_frame_crop, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 6:\n",
    "                mask_image = np.ones_like(game_frame)\n",
    "                source_pts = np.array([[854.0,480.0],[00.0,480.0],[0.0,0.0],[854.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(game_frame, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "\n",
    "    #aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    cv2.imshow('Estimation of the pose of arUco marker with intrinsic camera parameters',frame)\n",
    "    hw2_output_video.write(frame)\n",
    "    if cv2.waitKey(20) != -1:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "hw2_output_video.release()\n",
    "nggyu_cap.release()\n",
    "hyyyy_cap.release()\n",
    "esg_cap.release()\n",
    "ncat_cap.release()\n",
    "game_cap.release()\n",
    "vibe_cap.release()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "markerSize  = 6 #6cm\n",
    "cap = cv2.VideoCapture('ArUco_marker.mp4')\n",
    "arucoDict   = aruco.Dictionary_get(aruco.DICT_7X7_50)\n",
    "totalFrame   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))//2\n",
    "frameHeight  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))//2\n",
    "\n",
    "hw2_output_video = cv2.VideoWriter('myHW2Video.mp4', cv2.VideoWriter_fourcc(*'XVID'),\n",
    "                                   cap.get(cv2.CAP_PROP_FPS),\n",
    "                                   (frameWidth,frameHeight))  #輸出的影片\n",
    "\n",
    "nggyu_cap = cv2.VideoCapture('nggyu.mp4')\n",
    "hyyyy_cap = cv2.VideoCapture('hyyyy.mp4')\n",
    "esg_cap   = cv2.VideoCapture('esg.mp4')\n",
    "ncat_cap = cv2.VideoCapture('ncat.mp4')\n",
    "game_cap = cv2.VideoCapture('game.mp4')\n",
    "vibe_cap = cv2.VideoCapture('vibe.mp4')\n",
    "\n",
    "has_started = [False for _ in range(6)] #紀錄哪些id開始被偵測到了\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    _, nggyu_frame = nggyu_cap.read()\n",
    "    _, hyyyy_frame = hyyyy_cap.read()\n",
    "    _, esg_frame = esg_cap.read()\n",
    "    _, ncat_frame = ncat_cap.read()\n",
    "    _, game_frame = game_cap.read()\n",
    "    _, vibe_frame = vibe_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame,(frameWidth,frameHeight))\n",
    "    frame = cv2.undistort(frame, charuco_cameraMatrix, charuco_distCoeffs)\n",
    "\n",
    "    # #把nggyu影片貼合到一張新影像的左上角\n",
    "    # nggyu_frame_full = np.zeros((frame.shape[0], frame.shape[1], frame.shape[2]),dtype=np.uint8)\n",
    "    # nggyu_frame_full[:360,:480]=nggyu_frame[:360,90:90+480]\n",
    "    #\n",
    "    # #把hyyyy影片貼合到一張新影像的左上角\n",
    "\n",
    "    #這些影片有黑邊，所以把他們切掉\n",
    "    nggyu_frame_crop = np.zeros((nggyu_frame.shape[0], 460, nggyu_frame.shape[2]),dtype=np.uint8)\n",
    "    nggyu_frame_crop[:,:,:]=nggyu_frame[:,90:550,:]\n",
    "\n",
    "    ncat_frame_crop = np.zeros((ncat_frame.shape[0], 550, ncat_frame.shape[2]),dtype=np.uint8)\n",
    "    ncat_frame_crop[:,:,:]=ncat_frame[:,85:635,:]\n",
    "\n",
    "    esg_frame_crop = np.zeros((360, esg_frame.shape[1], esg_frame.shape[2]),dtype=np.uint8)\n",
    "    esg_frame_crop[:,:,:]=esg_frame[60:420,:,:]\n",
    "\n",
    "\n",
    "\n",
    "    #print(nggyu_frame_crop.shape)\n",
    "\n",
    "    (corners, ids, rejected) = aruco.detectMarkers(frame, arucoDict, parameters=arucoParams)\n",
    "\n",
    "    if len(corners) > 0:\n",
    "        #aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "        rvects, tvects, _ = aruco.estimatePoseSingleMarkers(corners, markerSize, charuco_cameraMatrix, charuco_distCoeffs)\n",
    "        for corner,id in zip(corners,ids):\n",
    "            if id == 1:\n",
    "                mask_image = np.ones_like(vibe_frame)\n",
    "                source_pts = np.array([[640.0,360.0],[0.0,360.0],[0.0,0.0],[640.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(vibe_frame, M, (frameWidth, frameHeight), flags=cv2.INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 2:\n",
    "                mask_image = np.ones_like(esg_frame_crop)\n",
    "                source_pts = np.array([[640.0,360.0],[0.0,360.0],[0.0,00.0],[640.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(esg_frame_crop, M, (frameWidth, frameHeight), flags=cv2.INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 3:\n",
    "                mask_image = np.ones_like(nggyu_frame_crop)\n",
    "                source_pts = np.array([[460,360.0],[0.0,360.0],[0.0,0.0],[460.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(nggyu_frame_crop, M, (frameWidth, frameHeight), flags=cv2.INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 4:\n",
    "                mask_image = np.ones_like(hyyyy_frame)\n",
    "                source_pts = np.array([[480.0,360.0],[0.0,360.0],[0.0,0.0],[480.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(hyyyy_frame, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 5:\n",
    "                mask_image = np.ones_like(ncat_frame_crop)\n",
    "                source_pts = np.array([[550.0,480.0],[0.0,480.0],[0.0,0.0],[550.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(ncat_frame_crop, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 6:\n",
    "                mask_image = np.ones_like(game_frame)\n",
    "                source_pts = np.array([[854.0,480.0],[00.0,480.0],[0.0,0.0],[854.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(game_frame, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "\n",
    "    #aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    cv2.imshow('Estimation of the pose of arUco marker with intrinsic camera parameters',frame)\n",
    "    hw2_output_video.write(frame)\n",
    "    if cv2.waitKey(20) != -1:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "hw2_output_video.release()\n",
    "nggyu_cap.release()\n",
    "hyyyy_cap.release()\n",
    "esg_cap.release()\n",
    "ncat_cap.release()\n",
    "game_cap.release()\n",
    "vibe_cap.release()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m markerSize  \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m6\u001B[39m \u001B[38;5;66;03m#6cm\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m cap \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241m.\u001B[39mVideoCapture(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mArUco_marker.mp4\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m arucoDict   \u001B[38;5;241m=\u001B[39m aruco\u001B[38;5;241m.\u001B[39mDictionary_get(aruco\u001B[38;5;241m.\u001B[39mDICT_7X7_50)\n\u001B[1;32m      4\u001B[0m totalFrame   \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(cap\u001B[38;5;241m.\u001B[39mget(cv2\u001B[38;5;241m.\u001B[39mCAP_PROP_FRAME_COUNT))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "markerSize  = 6 #6cm\n",
    "cap = cv2.VideoCapture('ArUco_marker.mp4')\n",
    "arucoDict   = aruco.Dictionary_get(aruco.DICT_7X7_50)\n",
    "totalFrame   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))//2\n",
    "frameHeight  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))//2\n",
    "\n",
    "hw2_output_video = cv2.VideoWriter('myHW2Video.mp4', cv2.VideoWriter_fourcc(*'XVID'),\n",
    "                                   cap.get(cv2.CAP_PROP_FPS),\n",
    "                                   (frameWidth,frameHeight))  #輸出的影片\n",
    "\n",
    "nggyu_cap = cv2.VideoCapture('nggyu.mp4')\n",
    "hyyyy_cap = cv2.VideoCapture('hyyyy.mp4')\n",
    "esg_cap   = cv2.VideoCapture('esg.mp4')\n",
    "ncat_cap = cv2.VideoCapture('ncat.mp4')\n",
    "game_cap = cv2.VideoCapture('game.mp4')\n",
    "vibe_cap = cv2.VideoCapture('vibe.mp4')\n",
    "\n",
    "has_started = [False for _ in range(6)] #紀錄哪些id開始被偵測到了\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    _, nggyu_frame = nggyu_cap.read()\n",
    "    _, hyyyy_frame = hyyyy_cap.read()\n",
    "    _, esg_frame = esg_cap.read()\n",
    "    _, ncat_frame = ncat_cap.read()\n",
    "    _, game_frame = game_cap.read()\n",
    "    _, vibe_frame = vibe_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame,(frameWidth,frameHeight))\n",
    "    frame = cv2.undistort(frame, charuco_cameraMatrix, charuco_distCoeffs)\n",
    "\n",
    "    # #把nggyu影片貼合到一張新影像的左上角\n",
    "    # nggyu_frame_full = np.zeros((frame.shape[0], frame.shape[1], frame.shape[2]),dtype=np.uint8)\n",
    "    # nggyu_frame_full[:360,:480]=nggyu_frame[:360,90:90+480]\n",
    "    #\n",
    "    # #把hyyyy影片貼合到一張新影像的左上角\n",
    "\n",
    "    #這些影片有黑邊，所以把他們切掉\n",
    "    nggyu_frame_crop = np.zeros((nggyu_frame.shape[0], 460, nggyu_frame.shape[2]),dtype=np.uint8)\n",
    "    nggyu_frame_crop[:,:,:]=nggyu_frame[:,90:550,:]\n",
    "\n",
    "    ncat_frame_crop = np.zeros((ncat_frame.shape[0], 550, ncat_frame.shape[2]),dtype=np.uint8)\n",
    "    ncat_frame_crop[:,:,:]=ncat_frame[:,85:635,:]\n",
    "\n",
    "    esg_frame_crop = np.zeros((360, esg_frame.shape[1], esg_frame.shape[2]),dtype=np.uint8)\n",
    "    esg_frame_crop[:,:,:]=esg_frame[60:420,:,:]\n",
    "\n",
    "\n",
    "\n",
    "    #print(nggyu_frame_crop.shape)\n",
    "\n",
    "    (corners, ids, rejected) = aruco.detectMarkers(frame, arucoDict, parameters=arucoParams)\n",
    "\n",
    "    if len(corners) > 0:\n",
    "        #aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "        rvects, tvects, _ = aruco.estimatePoseSingleMarkers(corners, markerSize, charuco_cameraMatrix, charuco_distCoeffs)\n",
    "        for corner,id in zip(corners,ids):\n",
    "            if id == 1:\n",
    "                mask_image = np.ones_like(vibe_frame)\n",
    "                source_pts = np.array([[640.0,360.0],[0.0,360.0],[0.0,0.0],[640.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(vibe_frame, M, (frameWidth, frameHeight), flags=cv2.INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 2:\n",
    "                mask_image = np.ones_like(esg_frame_crop)\n",
    "                source_pts = np.array([[640.0,360.0],[0.0,360.0],[0.0,00.0],[640.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(esg_frame_crop, M, (frameWidth, frameHeight), flags=cv2.INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 3:\n",
    "                mask_image = np.ones_like(nggyu_frame_crop)\n",
    "                source_pts = np.array([[460,360.0],[0.0,360.0],[0.0,0.0],[460.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(nggyu_frame_crop, M, (frameWidth, frameHeight), flags=cv2.INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 4:\n",
    "                mask_image = np.ones_like(hyyyy_frame)\n",
    "                source_pts = np.array([[480.0,360.0],[0.0,360.0],[0.0,0.0],[480.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(hyyyy_frame, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 5:\n",
    "                mask_image = np.ones_like(ncat_frame_crop)\n",
    "                source_pts = np.array([[550.0,480.0],[0.0,480.0],[0.0,0.0],[550.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(ncat_frame_crop, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "            if id == 6:\n",
    "                mask_image = np.ones_like(game_frame)\n",
    "                source_pts = np.array([[854.0,480.0],[00.0,480.0],[0.0,0.0],[854.0,0.0]])\n",
    "                dest_pts = np.array(corner)\n",
    "                M, mask = cv2.findHomography(source_pts,dest_pts, cv2.RANSAC,5.0)\n",
    "                warped = cv2.warpPerspective(game_frame, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                mask_warped = cv2.warpPerspective(mask_image, M, (frameWidth, frameHeight), flags=cv2.  INTER_CUBIC)\n",
    "                frame[np.where(mask_warped>0)] = warped[np.where(mask_warped>0)]\n",
    "\n",
    "    #aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    cv2.imshow('Estimation of the pose of arUco marker with intrinsic camera parameters',frame)\n",
    "    hw2_output_video.write(frame)\n",
    "    if cv2.waitKey(20) != -1:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "hw2_output_video.release()\n",
    "nggyu_cap.release()\n",
    "hyyyy_cap.release()\n",
    "esg_cap.release()\n",
    "ncat_cap.release()\n",
    "game_cap.release()\n",
    "vibe_cap.release()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}